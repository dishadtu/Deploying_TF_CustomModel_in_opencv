{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOf4jgQdBBg7RjE/utI/ytO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dishadtu/Deploying_TF_CustomModel_in_opencv/blob/main/Deploying_TF_CustomModel_in_opencv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "_RRE13fKFj9e",
        "outputId": "94520fb4-1f79-4bf8-a1ab-8007686b6eb7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-591cd9dfd889>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;31m# Read in the frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0mret_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0mcvNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswapRB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "# Project: Eating Utensil Detector Using TensorFlow and OpenCV\n",
        "# Author: Addison Sears-Collins\n",
        "# Date created: August 1, 2021\n",
        "# Description: This program detects forks, spoons, and knives\n",
        " \n",
        "import cv2 as cv # OpenCV computer vision library\n",
        "import numpy as np # Scientific computing library \n",
        "from google.colab.patches import cv2_imshow \n",
        "#  classes = ['person','bicycle','car','motorcycle','airplane' ,'bus','train','truck','boat' ,'traffic light','fire hydrant',\n",
        "#    'stop sign','parking meter','bench','bird','cat','dog','horse','sheep','cow','elephant','bear','zebra','giraffe' ,\n",
        "#    'backpack','umbrella','handbag' ,'tie','suitcase','frisbee' ,'skis','snowboard','sports ball' ,'kite',\n",
        "#    'baseball bat','baseball glove','skateboard','surfboard','tennis rack','bottle','wine glass','cup','fork','knife',\n",
        "#    'spoon','bowl','banana','apple' ,'sandwich','orange','broccoli','carrot','hot dog','pizza' ,'donut' ,'cake',\n",
        "#    'chair' ,'couch' ,'potted plant','bed','dining table','toilet','tv','laptop','mouse','remote','keyboard',\n",
        "#    'cell phone','microwave','oven','toaster','sink','refrigerator','book','clock','vase','scissors' ,'teddy bear',\n",
        "#    'hair drier','toothbrush']\n",
        " \n",
        "# Just use a subset of the classes\n",
        "classes = [\"background\", \"person\", \"bicycle\", \"car\", \"motorcycle\",\n",
        "  \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\",\n",
        "  \"unknown\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\",\n",
        "  \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"unknown\", \"backpack\",\n",
        "  \"umbrella\", \"unknown\", \"unknown\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\",\n",
        "  \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\",\n",
        "  \"surfboard\", \"tennis racket\", \"bottle\", \"unknown\", \"wine glass\", \"cup\", \"fork\", \"knife\",\n",
        "  \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\",\n",
        "  \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"unknown\", \"dining table\",\n",
        "  \"unknown\", \"unknown\", \"toilet\", \"unknown\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\",\n",
        "  \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"unknown\",\n",
        "  \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\" ]\n",
        " \n",
        "# Colors we will use for the object labels\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        " \n",
        "# Open the webcam\n",
        "cam = cv.VideoCapture('./forks_knives.mp4')\n",
        "\n",
        "\n",
        "frame_width = int(cam.get(3))\n",
        "frame_height = int(cam.get(4))\n",
        "   \n",
        "size = (frame_width, frame_height)\n",
        "\n",
        "utensilvideo = cv.VideoWriter('utensildetect.avi', \n",
        "                         cv.VideoWriter_fourcc(*'MJPG'),\n",
        "                         10, size)      \n",
        "\n",
        "pb  = './frozen_inference_graph.pb'\n",
        "pbt = './ssd_inception_v2_coco_2017_11_17.pbtxt'\n",
        " \n",
        "# Read the neural network\n",
        "cvNet = cv.dnn.readNetFromTensorflow(pb,pbt)   \n",
        " \n",
        "while True:\n",
        " \n",
        "  # Read in the frame\n",
        "  ret_val, img = cam.read()\n",
        "  rows = img.shape[0]\n",
        "  cols = img.shape[1]\n",
        "  cvNet.setInput(cv.dnn.blobFromImage(img, size=(300, 300), swapRB=True, crop=False))\n",
        " \n",
        "  # Run object detection\n",
        "  cvOut = cvNet.forward()\n",
        " \n",
        "  # Go through each object detected and label it\n",
        "  for detection in cvOut[0,0,:,:]:\n",
        "    score = float(detection[2])\n",
        "    if score > 0.3:\n",
        " \n",
        "      idx = int(detection[1])   # prediction class index. \n",
        " \n",
        "      # If you want all classes to be labeled instead of just forks, spoons, and knives, \n",
        "      # remove this line below (i.e. remove line 65)\n",
        "      if classes[idx] == 'fork' or classes[idx] == 'spoon' or classes[idx] == 'knife':          \n",
        "        left = detection[3] * cols\n",
        "        top = detection[4] * rows\n",
        "        right = detection[5] * cols\n",
        "        bottom = detection[6] * rows\n",
        "        cv.rectangle(img, (int(left), int(top)), (int(right), int(bottom)), (23, 230, 210), thickness=2)\n",
        "            \n",
        "        # draw the prediction on the frame\n",
        "        label = \"{}: {:.2f}%\".format(classes[idx],score * 100)\n",
        "        y = top - 15 if top - 15 > 15 else top + 15\n",
        "        cv.putText(img, label, (int(left), int(y)),cv.FONT_HERSHEY_SIMPLEX, 0.5, colors[idx], 2)\n",
        " \n",
        "  # Display the frame\n",
        "  #cv2_imshow(img)\n",
        "  utensilvideo.write(img)\n",
        "  # Press ESC to quit\n",
        "  if cv.waitKey(1) == 27: \n",
        "    break\n",
        " \n",
        "# Stop filming\n",
        "cam.release()\n",
        " \n",
        "# Close down OpenCV\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqv-EcAuJ5gV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}